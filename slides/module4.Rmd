---
title: 'Module 4: Relationships between qualitative variables'
author: "Jeroen Claes"
output:
  word_document:
    toc: no
  revealjs::revealjs_presentation:
    css: white.css
    self_contained: no
    transition: none
  html_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=TRUE, message=FALSE, warning=FALSE, error=FALSE, fig.height = 3, dpi = 300)
library(pander)
library(dplyr)
library(ggplot2)
```

## About this course 
- Four modules:
    - Introduction to R (Module 1)
    - Viewing, manipulating, and exporting tabular data (Module 2)
    - Exploring qualitative variables (Module 3)
    - Exploring the relationships between qualitative variables (This module)

## In this module
- Cross-tabulation: the basic tool to explore relations between qualitative variables
- Chi-square test of independence
- Fisher exact test
- Effect sizes for relations between qualitative variables
- Plots to explore the associations between qualitative variables 
- Reporting on associations between qualitative variables

##  Cross-tabulation: the basic tool to explore relations between qualitative variables
##  Cross-tabulation: the basic tool to explore relations between qualitative variables
##  Data
- We will be working with a dataset by Claes (2017)
    - Corpus investigation into existential agreement variation in Peninsular Spanish
    - Data drawn from *Twitter* and *Corpus Oral y Sonoro del Espa√±ol Rural (COSER)*
    - Random sample of 500 lines from the dataset
  
```{r data, eval=TRUE}
library(readr)
library(dplyr)
dataSet <- read_csv("http://www.jeroenclaes.be/r_crashcourse_for_linguists/datasets/class3_claes_2017.csv")
head(dataSet)
```

##  Crosstabulation (1/2)
- To explore the relationship between two qualitative variables, we have to count how many times each combination of the two variables occur
- This is called `crosstabulation`
- The output table is called a `contingency table`
- This can be done with the `table` function
- So, to count the number of times the `singular` and the `plural` existential occur in each of the `negation` groups, we use:
```{r table1, eval=TRUE}
# 'x' axis first (groups/independent variable), then 'y' axis (dependent variable)
table(dataSet$negation, dataSet$type)
```

##  Crosstabulation (2/2)
- Absolute counts are nice, but we're usually interested in the proportions of one option vs another
- This is what `prop.table` does. It takes two arguments:
    - A table
    - A `margin`:
        - `1` calculate the proportions by row (each **row** sums 1)
        - `2` calculate the proportions by column (each **column** sums 1)

```{r table2, eval=TRUE}
# 'x' axis first (groups/independent variable), then 'y' axis (dependent variable)
tab<-table(dataSet$negation, dataSet$type)
# proportions by row
prop.table(tab, 1)
# proportions by column
prop.table(tab, 2)
```

## Taking stock and exercises
- In this part you have learned:
    - How to create a contingency table
- There's a first excercise waiting for you at : https://www.jeroenclaes.be/r_crashcourse_for_linguists/module4.html, under *1. Loading and exploring the data*, *2.1 Frequency of /r/ by store*, *3.1 Frequency of /r/ by emphasis*, and *4.1 Frequency of /r/ by word*

## Inferential statistics and hypothesis testing

## Inferential statistics and hypothesis testing
- Inferential statistics tries to infer a property of a population by studying a sample
- Most often, we try to test a hypothesis about a property of a population by analyzing a sample

## Hypothesis testing (1/2)
- Before collecting data it is important to have:
    1. A research question: 
    - *Does the verb tense affect the occurrence rates of pluralized existential* haber *in Peninsular Spanish?* 
    2. Hypotheses: (theoretically motivated) tentative answers to these research questions: 
        - *The verb tense conditions the occurrence rates of pluralized existential* haber *in Peninsular Spanish* 

## Hypothesis testing (2/2)
- Each hypothesis (called *alternative hypothesis*) has its *null hypothesis*:  
    - *There is no effect of the verb tense on the occurrence rates of pluralized existential* haber *in Peninsular Spanish* 
- A hypothesis test tries to estimate the probability of obtaining the observed or more extreme results assuming the null hypothesis
- This way, it tries to establish wheather the difference between the groups 
    - is reliably large
    - is larger than would be predicted by chance

##  Hypothesis tests for associations between qualitative variables
##  Chi-square test of independence (1/5)
- The following table shows that there is a sizeable difference between the frequencies of the singular and the plural existential the two tense groups

```{r table3a, eval=TRUE}
# 'x' axis first (groups/independent variable), then 'y' axis (dependent variable)
tab<-table(dataSet$tense, dataSet$type)
# proportions by row
prop.table(tab, 1)
```

##  Chi-square test of independence (2/5)
- But is this difference reliably large? To test this, we need to perform a `Chi-squared test of independence`
- The `null hypothesis` of this test is that there is no association between the variables:
    - *There is no influence of the verb tense on the occurrence rate of singular and plural existential* haber
- The test compares the `observed frequency` to the frequency you would expect by chance (`the expected frequency`) to see how likely the results are

##  Chi-square test of independence (3/5)
- To get the expected frequency for a table cell, we need to add the `marginal frequencies` to the table
- Marginal frequencies are the row and column totals
- We can get the marginal frequencies with `rowSums` and `colSums`
```{r table3, eval=TRUE}
tab <- table(dataSet$tense, dataSet$type)
colSum<- colSums(tab)
rowSum<-rowSums(tab)
```

##  Chi-square test of independence (4/5)
- For the cell in column 1, row 1, the expected frequency can be found with the following formula:
```{r table4, eval=TRUE}
sampleSize <- sum(tab)
(colSum[1]/sampleSize) * (rowSum[1]/sampleSize) * sampleSize
```

##  Chi-square test of independence (5/5)
- Basically, the chi-square test functions as follows:
    - Calculate the expected frequency for each cell
    - Substract the expected frequency from the observed frequency. The resulting number is the `residual`
    - Divide this number by the square root of the expected frequency. The resulting number is the `Pearson residual`
    - Square all Pearson residuals and sum them. The resulting number is the `Chi-squared statistic`. 
    - Look up the chi-squared value in a chi-squared probability table. The degrees of freedom are the number of rows in the table, minus one.
- The R function `chisq.test` does all of that for us

##  Assumptions of the Chi-square test of independence
- The sample is randomly selected from the population of interest and the observations are independent. 
- Every observation can be classifed into exactly one category according to the criterion represented by each variable (Levshina, 2015: 212)
- The expected frequency for all cells is greater than 5
- The numbers in the table are counts, not proportions (**NEVER** run association tests on percentages!)

##  Performing a Chi-square test of independence in R (1/4)
- The function `chisq.test` takes two factor or character columns as its arguments
- It also accepts a matrix or a table of numeric values
```{r chisq.1, eval=TRUE}
chisq.test(dataSet$tense, dataSet$type)
```
 
##  Performing a Chi-square test of independence in R (2/4)
- If you run the test on proportions, you end up with a p-value of 1
```{r chisq.3, eval=TRUE}
chisq.test(prop.table(table(dataSet$tense, dataSet$type),2))
```

##  Performing a Chi-square test of independence in R (3/4)
- If you want to inspect the `expected frequencies`, you can pull them out of the test (or calculate them by hand with the formula above)
- Remember, if your expected frequency in one of the cells is lower than 5, the Chisq-test is not appropriate.
- R will fire the following warning when this is the case:
    - `Chi-squared approximation may be incorrect`
```{r chisq.21, eval=TRUE}
chisq.test(dataSet$tense, dataSet$type)$expected
```

##  Performing a Chi-square test of independence in R (4/4)
- The `chisq.test` also provides access to the residuals, the difference between the predicted and the expected values
- To compare the residuals in a meaningful way, they are standardized by dividing the residuals by the square root of their variance
- If we know the values of the standardized residuals, we may gain insight into which cells contributed significantly to the p-value
- `Standardized residuals` greater than `1.96`/smaller than `-1.96` indicate that a cell contributed significantly to the chi-squared value at p < 0.05
- If only one "odd" table cell contributes nearly all of the chi-squared (without you expecting it to do so on theoretical grounds), there may a data imbalance issue you will have to investigate further. This is more likely to occur in larger-dimensionality tables
```{r chisq.2, eval=TRUE}
chisq.test(dataSet$tense, dataSet$type)$stdres
```    

##  Fisher-Yates exact test
##  Fisher-Yates exact test
- When one of your expected frequencies is lower than 5, it is better to perform a Fisher-Yates exact test
```{r fisherYates, eval=TRUE}
fisher.test(dataSet$negation, dataSet$type)
```


## About p < 0.05 (1/3)
- Hypothesis tests output estimates of the probability of finding a test statistic (e.g., chi-squared value) as extreme or more extreme than the one we find assuming the null hypothesis of no association.
- To interpret this probability, it is usually compared to a pre-defined **alpha level**:
    - A common value is 0.05
    - Expresses that we will accept the null hypothesis if there is a 5% probability (1/20 chance) that it is true
- If the probability is lower than the alpha-level, we *reject* the null hypothesis 
- If the probability is higher, we are forced to accept the null hypothesis
- Here we find that p < 0.05, so we reject the null hypothesis: 
    - There is less than a 5% chance of finding a result as extreme or more extreme assuming the null hypothesis of no association between negation and *haber* pluralization

## About p < 0.05 (2/3)
- It is important to determine your alpha-level carefully:
    - Too strict: too many *Type I errors* (false positives: we reject the null, but it is true)
    - Too relaxed: too many *Type II errors* (false negatives: we accept the null, but it is false)
- For most tests, the p-value will be smaller for larger samples. For large samples you should use lower alpha-levels (0.01 or 0.001)

## About p < 0.05 (3/3)
- Observe that our actual hypothesis was only tested indirectly, in two ways:
  - We do not test the hypothesis, but rather the null hypothesis
  - We do not test the null hypothesis, but rather the probability of obtaining the same or a more extreme test statistic assuming the null hypothesis
 
## A note on unethical practices
- You will potentially make a fool out of yourself is you start comparing all possible groups in your data until you find some significant result. This is called *p-value hacking* and it is dangerous. Hypothesis testing methods become **useless** when used to do anything else than testing theoretically motivated hypotheses.
- It is unethical to tamper with your alpha-level once you have explored your results
- p-values depend on sample size. A non-significant result may become significant with more observations. It is **unethical** to keep adding data until you reach p < 0.05 

## Some common misconceptions
- There's no 'more' or 'less' significant. Either *p < alpha* or not
- p-values have **nothing** to do with the size of a difference between groups. Differences are **not** stronger when p-values are lower!
- p < 0.05 does **not** mean that your results are necesarily relevant. This is why you need solid hypotheses, subject matter knowledge, and good analytical skills
- p > 0.05 does **not** mean that your results are irrelevant.
- p < 0.05 does **not** mean that our hypothesis is true, or that our null hypothesis is false. p < 0.05 suggests that **for our sample** there is less than a 1/20 chance of finding data that supports the null hypothesis

## Taking stock and exercises
- In this part you have learned:
    - What the assumptions are of the Chi-squared test
    - How to perform it in R
    - When to perform a Fisher-Yates exact test
    - How to perform a Fisher-Yates exact test in R
    - Some clarifications about p-values 
- Please go to : http://www.jeroenclaes.be/r_crashcourse_for_linguists/module4.html, and perform the exercises under 2.2, 3.2, and 4.2 (*Validating the assumptions of the significance test*)

##  Effect sizes for relations between qualitative variables
##  Effect sizes for relations between qualitative variables (1/2)
- The p-values only tell you if the differences between the groups created by the X-variable is reliably large
- They tell you nothing about the sizes of the differences
- In the `vcd` package, the `assocstats` function computes several effect size statistics you can use to measure the strength of the differences
- They are computed on a `table`
```{r assocstats, eval=TRUE}
library(vcd)
tab<-table(dataSet$negation, dataSet$type)
assocstats(tab)
```

##  Effect sizes for relations between qualitative variables (2/2)
- For 2x2 tables, the measures are all identical (but not for e.g., 4x2 tables!)
    - Cram√©r‚Äôs *V* 
    - *œï* coefficient (phi) 
    - Contingency coefficient (used less often)
- For 2x2 tables, Cram√©r‚Äôs *V* and *œï*  range from 0 to 1
- For larger tables,  *œï* surpasses 1, so the function only returns Cram√©r‚Äôs *V* in that case (*œï* is `NA`)
- Rule of thumb for Cramer's *V* (and  *œï* in 2x2 tables):
    - 0: no association
    - 0-0.3: small effect size
    - 0.3-0.5: moderate effect
    - 0.5-0.99: large effect
    - 1: perfect association
    
```{r assocstats2, eval=TRUE}
library(vcd)
tab<-table(dataSet$province, dataSet$type)
assocstats(tab)
```

## Taking stock and exercises
- In this part you have learned:
    - What effect sizes are
    - How to compute effect sizes in R for differences between groups
- Please go to : https://www.jeroenclaes.be/r_crashcourse_for_linguists/module4.html, and perform the exercises under 2.3, 3.3, and 4.3 (*Significance test and effect size*)

##  Plots to explore the associations between qualitative variables 
##  Plots to explore the associations between qualitative variables (1/5)
- Barplots are the method of choice to plot associations between qualitative variables
- They come in three flavors:
    - Side-by side: (`position="dodge"`)
    - Stacked: (`position="stack"`)
    - Percentages: (`position="fill"`)
- Observe that we do not specify a `y`axis mapping here
```{r dodge, eval=TRUE}
ggplot(dataSet, aes(x=negation, fill=type, color=type)) + geom_bar(position = "dodge")
``` 

##  Plots to explore the associations between qualitative variables (2/5)
- Barplots are the method of choice to plot associations between qualitative variables
- They come in three varieties:
    - Side-by side: (`position="dodge"`)
    - Stacked: (`position="stack"`)
    - Percentages: (`position="fill"`)
- Observe that we do not specify a `y`axis mapping here
```{r stack, eval=TRUE}
ggplot(dataSet, aes(x=negation, fill=type, color=type)) + geom_bar(position = "stack")
``` 

##  Plots to explore the associations between qualitative variables (3/5)
- Barplots are the method of choice to plot associations between qualitative variables
- They come in three varieties:
    - Side-by side: (`position="dodge"`)
    - Stacked: (`position="stack"`)
    - Percentages: (`position="fill"`)
- Observe that we do not specify a `y`axis mapping here
- We add `scale_y_continous` to have nice percent-formatted y-axis labels (requires scales package)
```{r fill, eval=TRUE}
library(scales)
ggplot(dataSet, aes(x=negation, fill=type, color=type)) + 
  geom_bar(position = "fill") + 
  scale_y_continuous(labels = percent)
``` 

##  Plots to explore the associations between qualitative variables (4/5)
- We can add data labels to our `dodged` plots with a text layer
- For `stacked` and `filled` plots, this is very complicated

```{r stack0, eval=TRUE}
ggplot(dataSet, aes(x=negation, fill=type, color=type, label=..count..)) + 
  geom_bar(position = "dodge") + 
  geom_text(stat='count', position=position_dodge(width = 1), vjust=-1, color="black")
``` 

##  Plots to explore the associations between qualitative variables (5/5)
- `stacked` plots are great to show your readers how much tokens you have for each 'condition' (e.g., for negation, for different locations, ...)
- `dodged` plots are great to compare raw frequencies
- `filled` plots are preferred when you want to make the point that the relative frequency of your dependent variable varies by condition

## Taking stock and exercises
- In this part you have learned:
    - How to draw plots to compare counts across groups
- Please go to : https://www.jeroenclaes.be/r_crashcourse_for_linguists/module4.html, and perform the exercises under 2.4, 3.4, and 4.4 (*Plotting the differences*)

##  Reporting on associations between qualitative variables
##  Reporting on associations between qualitative variables
- Contingency table
- Test type (Chi-squared, Fisher-Yates exact)
- Test statistic (Chi-squared)
- Degrees of freedom
- Effect sizes
- Plots

## Taking stock and module-final project
## Taking stock and module-final project
- In this module you have learned:
    - How to perform cross-tabulation
    - How to perform a chi-square test of independence
    - How to perform a Fisher-Yates exact test
    - How to calculate effect sizes for relations between qualitative variables
    - How to create plots to explore the associations between qualitative variables
    - How to report on the associations between qualitative variables 
- Please go to: https://www.jeroenclaes.be/r_crashcourse_for_linguists/module4.html and take the *5. Quiz*

##  Module-final project
- Return to your script file
- Translate your research questions into hypotheses that involve counts across two or more groups
- Create a contingency table to explore your research question and hypotheses
- Write the code you need in order to perform the adequate statistical tests to establish the significance and effect sizes of the differences (if any) between the groups
- Create plots to explore the differences between the groups graphically

##  References
- Claes, J. (2017). Cognitive and geographic constraints on morphosyntactic variation: The variable agreement of presentational haber in Peninsular Spanish. *Belgian Journal of Linguistics* (31), 28-53.
- Levshina, N. (2015). *How to do linguistics with R: Data exploration and statistical analysis*. Amsterdam/Philadelphia, PA: John Benjamins.
- Urdan, T. (2010). *Statistics in Plain English*. New York NY/London: Routledge.