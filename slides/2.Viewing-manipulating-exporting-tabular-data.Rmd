---
title: 'Module 2: Viewing, manipulating, and exporting tabular data '
author: "Jeroen Claes"
output:
  revealjs::revealjs_presentation:
    css: white.css
    self_contained: no
    transition: none
  html_document:
    toc: no
  word_document:
   toc: no
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=TRUE, message=FALSE, warning=FALSE, error=FALSE, fig.height = 4, dpi = 300)
library(pander)
library(knitr)
library(tibble)
```


## About this course 
- Four goals:
    - Introduction to R (Module 1)
    - Viewing, manipulating, and exporting tabular data (This module)
    - Exploring qualitative variables (Module 3)
    - Exploring the relationships between qualitative variables (Module 4)
    - Elements of logistic regression (Module 5)

## In this module
- How to view tabular data
- How to manipulate tabular data
- How to export tabular data

# Data frames | The R alternative to Excel spreadsheets

## Data frames
- Up until now we have focused on getting data into R, but we haven't really played around yet with the resulting objects
- When you load a CSV or an Excel file into R, the resulting object is a `data.frame`:
    - A collection of vectors of the same length
    - Each vector is a column
    - There's no real notion of 'row' (in the sense of a level of organization that cuts across columns)

## Dataframe structure
- You can consult the internal structure of a data.frame (and any other object) by applying the fuction `str()` (from **str**ucture)

```{r dataStructure, eval=TRUE}
library(readr)
dataSet <- read_csv("http://www.jeroenclaes.be/statistics_for_linguistics/datasets/class3_claes_2017.csv")
str(dataSet)
```

## Viewing dataframes
- In RStudio, you can inspect/interact with the contents of a data.frame by calling the function `View` 

```{r ViewData, eval=FALSE}
View(dataSet)
```


## Computing the dimensions of dataframes
- With `dim` we compute the number of dimensions (columns and rows) 
- With `nrow` the number of rows
- With `ncol` the number of columns
```{r dimensions, eval=T}
dim(dataSet)
nrow(dataSet)
ncol(dataSet)
```

## Inspecting the first rows of a dataframe
- Often you will want to inspect the first couple of rows of a dataframe just to see how it looks like
- This can be done with the function `head`
- `head` takes two arguments: 
    - An object (dataframe, vector, or list)
    - Number of elements to show (defaults to 6)

```{r head, eval=T}
head(dataSet)
```    

## Inspecting the last rows of a dataframe
The function `tail` does the same thing as the function `head`, but it returns the last N rows of a dataframe or the last N items of a vector or list
```{r tail}
tail(dataSet, 10)
```

## Summarising a dataframe
The function `summary` prints a general overview of the values (minimum, maximum, median,mean,...) in a dataframe
```{r summary}
summary(dataSet)
```

## Taking stock and exercises
- In this part we've learned:
    - How to View a dataframe
    - How to print the number of dimensions of a dataframe
    - How to inspect the first couple of rows of a dataframe
    - How to inspect the last couple of rows of a dataframe
    - How to print a summary of a dataframe
- Please perform the exercise http://www.jeroenclaes.be/statistics_for_linguistics/class2.html (until `Exploring data.frames(1/2)`)

# Dplyr | A grammar of data manipulation

## Brief introduction to Dplyr (1/4)
- The R package Dplyr has two goals:
    - Providing a faster, less technical way of manipulating dataframes
    - Making your code easier to read, write, and understand by introducing a set of functions/verbs that look like plain English
    - We will consider:
        - `filter()` picks rows based on their values
        - `mutate()` adds new columns that are functions of existing variables
        - `select()` picks columns based on their names

## Brief introduction to Dplyr (2/4)
- To improve the readability of code, `Dplyr` promotes the use of pipes, written `%>%`
- `%>%` takes the return value of the expression on its left-hand side and passes it to the expression on its right-hand side
- This way, you never have to write nested function calls. Rather, you can simply write a series of commands, which pass the data from one function to the next

## Brief introduction to Dplyr (3/4)
- A quick example will show the difference
- Without pipes, it is harder to see what operations we are performing on the build-in `iris` dataset
``` {r nopipe}
head(tail(iris), 2)
```

## Brief introduction to Dplyr (4/4)
- A quick example will show the difference
- With pipes, the workflow immediately becomes clear:
    - Take the iris dataset
    - Take the last 6 rows
    - Take the first 2 rows 
    
``` {r withpipe}
iris %>%
  tail() %>%
  head(2)
```


# Basic `dplyr` verbs 

## Basic `dplyr` verbs: `filter` (1/3)
- The function  `filter` applies a filter to a dataframe. It returns only those rows for which a particular condition evaluates `TRUE`
- Here we extract only the rows for customer `67691762`
``` {r filter}
library(dplyr)
dataSet %>% 
        filter(corpus=="Twitter") %>%
        head()
```

## Basic `dplyr` verbs: `filter` (2/2)
- Other commonly used conditions are:
    - `duplicated()` - "is a duplicated value"
    - `!duplicated()`- "is not a duplicated value"
    - `is.na()`  - "is empty value"
    - `!is.na()` - "is **NOT** empty value"
    -  `<` - "smaller than"
    - `<=` - "smaller than or equal to"
    - `>` - "larger than"
    - `>=` - "larger than or equal to"
    - `%in%`  - "one of list" (e.g., `filter(province %in% c("Cádiz", "Barcelona", "Asturias"))`)
    - `%in%` with NOT operator (e.g., `filter(!customer %in% c("Cádiz", "Barcelona", "Asturias"))`) - "not one of list"

## Basic `dplyr` verbs: `mutate` (1/3)
- The function `mutate` can be used to create new columns or change the values of existing columns
- In general, it makes your code easier to read when you write a separate call to `mutate` for each column operation you perform

``` {r mutate}
dataSet %>% 
        mutate(mean_characters_before_noun=mean(characters_before_noun, na.rm=TRUE)) %>%
        head()
```

## Basic `dplyr` verbs: `mutate` (2/3)
- Often, you will use `mutate` in conjunction with `ifelse` to create new column values based on the value(s) of one or more other columns
``` {r mutate_ifelse}
dataSet %>% 
        mutate(nounPosition=ifelse(characters_before_noun ==0, "adjacent", "not-adjacent")) %>%
        head()
```

## Basic `dplyr` verbs: `mutate` (3/3)
- The base function `cut` can be used to divide numeric columns into intervals:
    - Square brackets indicate that the following number is part of the interval
    - Parentheses indicate that the preceding number does not form part of the interval

``` {r mutate_cut}
dataSet %>% 
        mutate(characters_before_noun=cut(characters_before_noun, breaks=c(-Inf, 0, 4, 10, 15, 20, Inf))) %>%
        head()
```

## Basic `dplyr` verbs: `select`
- The function `select` is used to select columns from a dataframe
- By prefixing one or more column names with `-`, you select all columns **except** those columns

``` {r select}
dataSet %>% 
        select(-noun) %>%
        head()
```

## Taking stock and exercises
- In this part, you have learned:
    - How to filter a dataframe using one or more conditions
    - How to add or alter columns in a dataframe
    - How to select columns from a dataframe using a list of column names, a negative list of column names, or partial matches


[[Excercises!!]]


# Recoding data | Revisiting `mutate` with extra functions
## Recoding data: `recode`
- Often you will find data values that are not very useful for your analysis, or you just want to try out something different
- The `dplyr`function `recode` allows you to specify a `old value` ==> `new value` mapping. This function can be used with `mutate` to make changes to the values of columns

```{r recode}
dataSet %>%
  mutate(broad.regions_recoded=recode(broad.regions, "East"="Perifery", "West"="Perifery", "South"="Perifery")) %>%
  head()
```

## Recoding data: `stringi` 
- The `stringi` package is a fast string manipulation package 
- Among other things, it allows you to perform find/replace

## Recoding data: `stri_replace_all_fixed`
- `stri_replace_all_fixed` searches the input vector for the string that is defined in the second argument and replaces it with the string defined in the third argument

```{r stri_replace_fixed}
library(stringi)
dataSet %>%
  mutate(state=stri_replace_all_fixed(state, "ñ", "n")) %>%
  head()
```

## Taking stock and exercises
- In this part we have learned:
    - How to recode columns, by manually specifying new values for existing values
    - How to perform find/replace for fixed strings with `stringi`
- There's an exercise waiting for you on the data science platform: `2.Data manipulation with tidyr and dplyr - Recoding data`



# Exporting data from R | Writing CSV and Excel files
## Exporting data from R: CSV files (1/2)
- Once you have read/manipulated a data table into R memory, you can also write it back out to a file
- To this end, we can use the `write_csv`, `write_csv2`, `write_tsv` or `write_delim` functions from the `readr` package
- In the simplest of cases, you simply specify:
    - The variable you want to export to csv
    - The path to the file you want to create

```{r write_csv, eval=FALSE}
library(readr)
library(readxl)
dataSet <- read_excel("datasets/corpus_futuro.xlsx", sheet = 1) %>%
  head(5)
write_csv(dataSet, "corpus_futuro.csv")
```



## Exporting data from R: Excel files (1/3)
- To export a data table to an Excel file, the `writexl` package is required

```{r installWriteXL, eval=FALSE}
install.packages("writexl")
library(writexl)
```


## Exporting data from R: Excel files (2/2)
- The syntax of this function is modeled after the `write_*` functions of the `readr` package
- For all practical purposes (simply getting data from R to Excel), all you need to specify is:
    - A data table 
    - A destination `.xlsx` file path

```{r write_xlsx_1_sheet, eval=FALSE}
write_xlsx(dataSet, "corpus_futuro.xlsx")
```

## Exporting data from R: `.rdata` files (1/3)
- A third option to load/save data are `.rdata` files, R's own file format
- Rdata files are especially useful for:
    - Really large data objects
    - Data objects you plan on using again later in R
    - Checkpointing long-running analyses
    - Saving object types other than data tables

## Exporting data from R: `.rdata` files (2/3)
- Saving one or more variables to `.rdata` can be done with the `save` function
- The file path to the `.rdata` file is specified in the `file` argument, **which has to be specified explicitly**
  
```{r saveFunction, eval=FALSE}
save(dataSet, file="corpus.rdata")
```

## Exporting data from R: `.rdata` files (3/3)
- Loading `.rdata` files back into memory is done with the `load` function
- This function takes a single argument: the file path to the `.rdata` file
- The variables (i.e., the object AND the name you gave it) become available in R memory after importing the `.rdata` file

```{r loadFunction, eval=FALSE}
load("corpus.rdata-*")
```

## Taking stock and exercises
- In this part, we have learned how to export data tables:
    - To CSV files
    - To Excel files
    - To `.rdata` files

# Module overview and module-final project
## Module overview 
- In this module, we have covered:
    - How to explore dataframes
    - How to manipulate dataframes
    - How to recode columns
    - How to export dataframes as CSV files
    - How to export dataframes as Excel spreadsheets
    - How to export objects as rdata files

## Module-final project 
- Return to your script file.
- Write code to perform the following tasks:
    - Print a summary of your dataset so you can get an idea of the values in it
    - Print the first 12 lines of your dataset
    - Print the last 5 lines of your dataset
    - View your dataset
    - Select the columns that you need to perform your analysis
    - Filter out the rows that you need to perform your analysis
    - Perform any recoding you may need to do 
    - Save your modified dataset as a Rdata file, an Excel file, and a CSV file
    
# Further reading
## Further reading (Free!)
- Grolemund, G., & Wickham, H. (2017). *R for data science: Visualize, model, transform, tidy, and import data*. New York, NY: O'Reilly. https://r4ds.had.co.nz/. 